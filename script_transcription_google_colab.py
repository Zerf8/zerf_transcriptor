# -*- coding: utf-8 -*-
"""script_transcription_google_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1...

# üèÜ Transcriptor ZERF (Edici√≥n Definitiva)
**Motor:** OpenAI Whisper Oficial (Modelo `large`)
**Configuraci√≥n:** Calidad M√°xima, Prompt Completo Anti-Alucinaciones
"""

# @title 1. Instalar Dependencias (Ejecutar una vez)
# @markdown Instala OpenAI Whisper, yt-dlp y FFmpeg.
import os
import subprocess
import sys

print("üì¶ Instalando dependencias de alto rendimiento...")
# Instalar OpenAI Whisper oficial (no faster-whisper) para m√°xima fiabilidad
subprocess.check_call([sys.executable, "-m", "pip", "install", "git+https://github.com/openai/whisper.git", "yt-dlp"])
subprocess.check_call(["apt", "update"])
subprocess.check_call(["apt", "install", "ffmpeg"])

import whisper
import yt_dlp
import re
import unicodedata
import gc
import torch
from google.colab import drive
from datetime import datetime

print("‚úÖ Entorno preparado. CUDA disponible:", torch.cuda.is_available())

# @title 2. Configurar y Montar Drive
# @markdown Monta Google Drive y define las carpetas de salida.

print("üìÇ Montando Google Drive...")
drive.mount('/content/drive', force_remount=True)

# CONFIGURACI√ìN DE RUTAS
DRIVE_BASE = "/content/drive/MyDrive/Transcripts_Barca"
FOLDER_SRT = os.path.join(DRIVE_BASE, "SRT_YouTube")
FOLDER_TXT = os.path.join(DRIVE_BASE, "TXT_NotebookLM")
FOLDER_AUDIO = os.path.join(DRIVE_BASE, "AUDIO_MP3")
LISTA_MAESTRA = os.path.join(DRIVE_BASE, "lista_maestra_videos.txt")

# Crear carpetas si no existen
for f in [FOLDER_SRT, FOLDER_TXT, FOLDER_AUDIO]:
    os.makedirs(f, exist_ok=True)
    print(f"   üìÅ Directorio verificado: {f}")

# @title 3. Motor de Transcripci√≥n (L√≥gica "Winner")
# @markdown Define las funciones clave para replicar la calidad de "whisper_large_prompt_completo".

def limpiar_nombre_archivo(texto):
    """Limpia el t√≠tulo para evitar problemas en sistemas de archivos"""
    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')
    texto = re.sub(r'[^\w\s-]', '', texto)
    texto = re.sub(r'[\s]+', '_', texto)
    return texto[:100] # Limitar longitud

def generar_nombre_final(info):
    """
    Genera el nombre estricto: YYMMDD_TITULO_ID
    Ej: 20260131_ELCHE_1_FC_BARCELONA_3_VUMNuQcfhmw
    """
    fecha = info.get('upload_date', datetime.now().strftime('%Y%m%d'))
    titulo = info.get('title', 'Video_Sin_Titulo')
    video_id = info.get('id', 'UnknownID')
    
    titulo_limpio = limpiar_nombre_archivo(titulo)
    return f"{fecha}_{titulo_limpio}_{video_id}"

def format_timestamp(seconds):
    """Formato SRT est√°ndar: 00:00:00,000"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

def write_srt(segments, path):
    """Escribe el archivo SRT desde los segmentos de OpenAI Whisper"""
    with open(path, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(segments, 1):
            start = format_timestamp(segment['start'])
            end = format_timestamp(segment['end'])
            text = segment['text'].strip()
            f.write(f"{i}\n{start} --> {end}\n{text}\n\n")

# PROMPT CRUDO (Contexto Cr√≠tico)
INITIAL_PROMPT = "Transcripci√≥n de an√°lisis del FC Barcelona. Jugadores: Lamine Yamal, Lewandowski, Cubars√≠, Ferm√≠n, Gavi, Pedri, Ara√∫jo, Kound√©, Raphinha, Ter Stegen, Pau V√≠ctor, Dani Olmo, Flick."

print("‚úÖ Funciones cargadas.")

# @title 4. EJECUTAR PROCESO DE TRANSCRIPCI√ìN
# @markdown Lee `lista_maestra_videos.txt` y procesa los videos.

# VARIABLE PARA LIMITAR EL N√öMERO DE VIDEOS (0 = Todos)
NUM_VIDEOS_LIMIT = 5 # @param {type:"integer"}

# Cargar Modelo (Solo una vez)
if 'model' not in globals():
    print("‚è≥ Cargando modelo OpenAI Whisper 'large' (puede tardar un poco)...")
    model = whisper.load_model("large")
    print("ü§ñ Modelo cargado en GPU.")

# Leer lista de videos
if not os.path.exists(LISTA_MAESTRA):
    print(f"‚ùå ERROR: No se encuentra {LISTA_MAESTRA}")
else:
    with open(LISTA_MAESTRA, 'r', encoding='utf-8') as f:
        # Leemos l√≠nea completa para extraer metadatos despu√©s
        all_videos = [line.strip() for line in f if '|' in line]
    
    # Aplicar l√≠mite
    if NUM_VIDEOS_LIMIT > 0:
        videos = all_videos[:NUM_VIDEOS_LIMIT]
        print(f"‚ö†Ô∏è Limitando a los primeros {NUM_VIDEOS_LIMIT} videos.")
    else:
        videos = all_videos
        
    print(f"üìã Encontrados {len(videos)} videos para procesar (Total disponible: {len(all_videos)}).")

    for i, line_raw in enumerate(videos, 1):
        try:
            # Parsear l√≠nea: URL | TITULO | DESCRIPCION
            parts = line_raw.split('|')
            url = parts[0].strip()
            title_hint = parts[1].strip() if len(parts) > 1 else ""
            desc_hint = parts[2].strip() if len(parts) > 2 else ""
            
            # Construir Prompt Enriquecido
            # SINTAXIS: Contexto espec√≠fico del video + Lista de vocabulario (INITIAL_PROMPT)
            # Limitamos la descripci√≥n para no exceder tokens (Whisper soporta ~224 tokens)
            current_prompt = f"{title_hint}. {desc_hint[:200]}. {INITIAL_PROMPT}"
            print(f"\nüé¨ Procesando [{i}/{len(videos)}]: {url}")
            print(f"   üí° Prompt Contextual: {title_hint}...")
            
            # 1. Obtener Metadatos (sin descargar a√∫n)
            with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
                info = ydl.extract_info(url, download=False)
            
            nombre_final = generar_nombre_final(info)
            audio_path = os.path.join(FOLDER_AUDIO, f"{nombre_final}.mp3")
            srt_path = os.path.join(FOLDER_SRT, f"{nombre_final}.srt")
            txt_path = os.path.join(FOLDER_TXT, f"{nombre_final}.txt")
            
            print(f"   üè∑Ô∏è Nombre: {nombre_final}")

            # 2. Descargar Audio si no existe
            if not os.path.exists(audio_path):
                print("   ‚¨áÔ∏è Descargando audio (MP3)...")
                ydl_opts = {
                    'format': 'bestaudio/best',
                    'outtmpl': audio_path.replace('.mp3', ''),
                    'postprocessors': [{
                        'key': 'FFmpegExtractAudio',
                        'preferredcodec': 'mp3',
                        'preferredquality': '192',
                    }],
                    'quiet': True
                }
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([url])
            else:
                print("   ‚úÖ Audio ya existente.")

            # 3. Transcribir
            print("   üé§ Transcribiendo con OpenAI Whisper Large...")
            # Usamos prompt din√°mico
            result = model.transcribe(
                audio_path, 
                language="es", 
                initial_prompt=current_prompt,
                verbose=False
            )

            # 4. Guardar SRT (Subt√≠tulos)
            write_srt(result['segments'], srt_path)
            print(f"   üíæ SRT Guardado: {os.path.basename(srt_path)}")

            # 5. Guardar TXT (Texto plano para NotebookLM)
            texto_completo = result['text'].strip()
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(f"VIDEO: {info.get('title')}\nURL: {url}\n\n{texto_completo}")
            print(f"   üíæ TXT Guardado: {os.path.basename(txt_path)}")

            # Limpieza de memoria
            gc.collect()
            torch.cuda.empty_cache()

        except Exception as e:
            print(f"   ‚ùå ERROR procesando {url}: {str(e)}")

print("\nüéâ ¬°TODO TERMINADO!")
